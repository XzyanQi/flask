# -*- coding: utf-8 -*-
"""NLP_Translate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a8FIZFsbWpsPfCVair13zMbVV7dgoWQf

# **Capstone Project** (CC25-CF254)

**Mindfulness**

Mindfulness is a chatbot application designed to help college students recognize their emotional codition. This chatbot can ask questions about mood, sleep patterns, stress level, and their daily activities.

## **Import All Packages/Library dan Install package**
"""


# pip install PySastrawi  # Pasang PySastrawi untuk stemming bahasa Indonesia
# pip install transformers faiss-cpu sentencepiece datasets  # Pasang transformers untuk NLP modern
# pip install tensorflow  # Pasang tensorflow untuk deep learning
# pip install nltk  # Pasang nltk untuk natural language toolkit
# pip install scikit-learn  # Pasang scikit-learn untuk machine learning

import nltk
import re
import string
import numpy as np
import pandas as pd
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from transformers import AutoTokenizer, TFAutoModel
import faiss
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf

nltk.download('punkt')
nltk.download('stopwords')

# Preprocessing text
def preprocess_text(text):
    if isinstance(text, str):
        text = text.lower()
        text = text.translate(str.maketrans('', '', string.punctuation))
        text = re.sub(r'\d+', '', text)
        stop_words = set(stopwords.words('indonesian'))
        words = word_tokenize(text)
        return ' '.join([word for word in words if word not in stop_words])
    return ''

# Load dataset
data = pd.read_csv('translated_train.csv')
data['translated_response'] = data['translated_response'].fillna("Sorry, I have no answer for this.")
data['processed_context'] = data['translated_context'].apply(preprocess_text)
data['processed_response'] = data['translated_response'].apply(preprocess_text)
data = data.drop_duplicates(subset=['processed_context', 'processed_response']).reset_index(drop=True)
df_terjemahan = data.copy()

# Load model
model_name = "indobenchmark/indobert-lite-base-p1"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = TFAutoModel.from_pretrained(model_name)

# Encoding function
def encode_text(text):
    clean_text = preprocess_text(text)
    inputs = tokenizer(clean_text, return_tensors='tf', padding=True, truncation=True, max_length=128)
    outputs = model(inputs)[0]  # Ambil last_hidden_state
    embeddings = tf.reduce_mean(outputs, axis=1)
    return embeddings.numpy().squeeze()

# Encode corpus
corpus_embeddings = np.array([encode_text(t) for t in df_terjemahan['processed_context']])
np.save('context_embeddings.npy', corpus_embeddings)

# Load embeddings
corpus_embeddings = np.load('context_embeddings.npy')

# Buat FAISS index
index = faiss.IndexFlatL2(corpus_embeddings.shape[1])
index.add(corpus_embeddings)

# Dapatkan embedding query
def get_query_embedding(text):
    clean_text = preprocess_text(text)
    inputs = tokenizer(clean_text, return_tensors='tf', padding=True, truncation=True, max_length=128)
    outputs = model(inputs)[0]
    pooled = tf.reduce_mean(outputs, axis=1)
    return pooled.numpy().reshape(1, -1)

# Ambil respons dengan fallback
def get_semantic_chatbot_response_with_fallback(query, df, index, similarity_threshold=1.0):
    query_emb = get_query_embedding(query)
    distances, indices = index.search(query_emb.astype('float32'), k=1)
    closest_distance = distances[0][0]
    closest_idx = indices[0][0]

    if closest_distance <= similarity_threshold:
        return df.iloc[closest_idx]['translated_response']
    else:
        return "Maaf, aku kurang memahami maksudmu. Bisa kamu jelaskan lebih lanjut?"

# Uji coba chatbot
queries = [
    "Saya merasa sangat sedih.",
    "Butuh bantuan untuk mengatasi kecemasan",
    "Bagaimana seseorang memulai proses konseling?"
]
SIMILARITY_THRESHOLD = 50.0

for i, query in enumerate(queries, start=1):
    print(f"Query Pengguna {i}: {query}")
    response = get_semantic_chatbot_response_with_fallback(query, df_terjemahan, index, similarity_threshold=SIMILARITY_THRESHOLD)
    print(f"Mindfulness {i}: {response}\n")
